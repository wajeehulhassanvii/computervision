{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "G - generative\n",
    "D - Discriminator\n",
    "\n",
    "G neural network, takes random noise signal and output some image, theif trying to steal\n",
    "D another neural network, rivaling generator, police trying to detect, understands what the generator is trying to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPLICATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generating images<br>\n",
    "image modification<br>\n",
    "super resolution<br>\n",
    "assisting artists<br>\n",
    "photo-realistic images<br>\n",
    "speech recognition<br>\n",
    "face aging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image generation is the main application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "imagesize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wajeeh-machine/anaconda3/envs/mytf2/lib/python3.7/site-packages/torchvision/transforms/transforms.py:279: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.Scale(imagesize),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(\n",
    "                                    (0.5, 0.5, 0.5),\n",
    "                                    (0.5, 0.5, 0.5)\n",
    "                                ),\n",
    "                               ]) # We create a list of transformations (scaling, tensor conversion, normalization) to apply to the input images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar-10-batches-py\n"
     ]
    }
   ],
   "source": [
    "! ls ../datasets/gan_cifar10/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = dset.CIFAR10(root = '../datasets/gan_cifar10/data',\n",
    "                      download = True, transform = transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataloader gives us data batch to batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size = batchsize,\n",
    "                                        shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights will take neural network and initialize weights for both networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining generator, its neural network and forward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        ''' initialize the generator neural network'''\n",
    "        super(G, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential( # We create a meta module of a neural network that will contain a sequence of modules (convolutions, full connections, etc.).\n",
    "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias = False), # We start with an inversed convolution.\n",
    "            nn.BatchNorm2d(512), # We normalize all the features along the dimension of the batch.\n",
    "            nn.ReLU(True), # We apply a ReLU rectification to break the linearity.\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False), # We add another inversed convolution.\n",
    "            nn.BatchNorm2d(256), # We normalize again.\n",
    "            nn.ReLU(True), # We apply another ReLU.\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False), # We add another inversed convolution.\n",
    "            nn.BatchNorm2d(128), # We normalize again.\n",
    "            nn.ReLU(True), # We apply another ReLU.\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False), # We add another inversed convolution.\n",
    "            nn.BatchNorm2d(64), # We normalize again.\n",
    "            nn.ReLU(True), # We apply another ReLU.\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias = False), # We add another inversed convolution.\n",
    "            nn.Tanh() # We apply a Tanh rectification to break the linearity and stay between -1 and +1.\n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        ''' it takes in the network, forward propagate and returns \n",
    "        the generated image'''\n",
    "        output = self.main(input) # forward propagate through whole nw\n",
    "        return output # return o/p containint generated image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### creating Generator object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (13): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG = G() # create generator object\n",
    "netG.apply(weights_init) # initialize all the weights of its neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining discriminator, its neural network and forward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''initialize discriminator neural network'''\n",
    "        super(D, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            \n",
    "        nn.Conv2d(3, 64, 4, 2, 1, bias = False),\n",
    "        nn.LeakyReLU(0.2, inplace = True),\n",
    "        nn.Conv2d(64, 128, 4, 2, 1, bias = False),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.LeakyReLU(0.2, inplace = True),\n",
    "        nn.Conv2d(128, 256, 4, 2, 1, bias = True),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.LeakyReLU(0.2, inplace = True),\n",
    "        nn.Conv2d(256, 512, 4, 2, 1, bias = False),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.LeakyReLU(0.2, inplace = True),\n",
    "        nn.Conv2d(512, 1, 4, 1, 0, bias = False),\n",
    "        nn.Sigmoid()\n",
    "            \n",
    "        )\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.main(input) # forward propagate through whole nw\n",
    "        return output.view(-1) # return output value b/w 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### creating discriminator object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.module.apply(fn) Applies fn recursively to every submodule (as returned by .children()) as well as self. Typical use includes initializing the parameters of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netD = D() # create discriminator object\n",
    "netD.apply(weights_init) # initialize all the weightsof its neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training DCGANs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss() # Criterion will measure the error between prediction and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer for the discriminator\n",
    "optimizerD = optim.Adam(netD.parameters(), lr= 0.0002,\n",
    "                        betas = (0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer for the generator\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = 0.0002,\n",
    "                       betas = (0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][0/782] Loss_D: 1.5275 Loss_G: 4.8386\n",
      "[0/25][1/782] Loss_D: 0.3197 Loss_G: 4.4910\n",
      "[0/25][2/782] Loss_D: 0.0574 Loss_G: 5.1611\n",
      "[0/25][3/782] Loss_D: 0.0340 Loss_G: 5.6326\n",
      "[0/25][4/782] Loss_D: 0.0118 Loss_G: 6.3019\n",
      "[0/25][5/782] Loss_D: 0.0086 Loss_G: 6.6130\n",
      "[0/25][6/782] Loss_D: 0.0065 Loss_G: 6.9921\n",
      "[0/25][7/782] Loss_D: 0.0054 Loss_G: 6.8979\n",
      "[0/25][8/782] Loss_D: 0.0039 Loss_G: 7.3516\n",
      "[0/25][9/782] Loss_D: 0.0032 Loss_G: 7.4955\n",
      "[0/25][10/782] Loss_D: 0.0034 Loss_G: 7.6257\n",
      "[0/25][11/782] Loss_D: 0.0033 Loss_G: 7.6747\n",
      "[0/25][12/782] Loss_D: 0.0034 Loss_G: 7.8878\n",
      "[0/25][13/782] Loss_D: 0.0031 Loss_G: 7.9162\n",
      "[0/25][14/782] Loss_D: 0.0025 Loss_G: 7.8785\n",
      "[0/25][15/782] Loss_D: 0.0025 Loss_G: 7.7412\n",
      "[0/25][16/782] Loss_D: 0.0025 Loss_G: 7.8952\n",
      "[0/25][17/782] Loss_D: 0.0024 Loss_G: 8.0970\n",
      "[0/25][18/782] Loss_D: 0.0025 Loss_G: 8.1430\n",
      "[0/25][19/782] Loss_D: 0.0029 Loss_G: 7.8425\n",
      "[0/25][20/782] Loss_D: 0.0021 Loss_G: 7.9945\n",
      "[0/25][21/782] Loss_D: 0.0020 Loss_G: 7.9775\n",
      "[0/25][22/782] Loss_D: 0.0018 Loss_G: 8.3290\n",
      "[0/25][23/782] Loss_D: 0.0018 Loss_G: 8.2828\n",
      "[0/25][24/782] Loss_D: 0.0017 Loss_G: 8.1518\n",
      "[0/25][25/782] Loss_D: 0.0016 Loss_G: 8.4262\n",
      "[0/25][26/782] Loss_D: 0.0019 Loss_G: 8.4640\n",
      "[0/25][27/782] Loss_D: 0.0016 Loss_G: 8.4454\n",
      "[0/25][28/782] Loss_D: 0.0015 Loss_G: 8.6099\n",
      "[0/25][29/782] Loss_D: 0.0014 Loss_G: 8.4993\n",
      "[0/25][30/782] Loss_D: 0.0020 Loss_G: 8.4722\n",
      "[0/25][31/782] Loss_D: 0.0014 Loss_G: 8.6762\n",
      "[0/25][32/782] Loss_D: 0.0012 Loss_G: 8.7340\n",
      "[0/25][33/782] Loss_D: 0.0014 Loss_G: 8.4606\n",
      "[0/25][34/782] Loss_D: 0.0012 Loss_G: 8.8204\n",
      "[0/25][35/782] Loss_D: 0.0010 Loss_G: 8.6649\n",
      "[0/25][36/782] Loss_D: 0.0016 Loss_G: 8.6314\n",
      "[0/25][37/782] Loss_D: 0.0011 Loss_G: 8.9020\n",
      "[0/25][38/782] Loss_D: 0.0009 Loss_G: 8.7286\n",
      "[0/25][39/782] Loss_D: 0.0008 Loss_G: 9.1087\n",
      "[0/25][40/782] Loss_D: 0.0009 Loss_G: 8.8392\n",
      "[0/25][41/782] Loss_D: 0.0007 Loss_G: 9.0438\n",
      "[0/25][42/782] Loss_D: 0.0011 Loss_G: 8.8893\n",
      "[0/25][43/782] Loss_D: 0.0009 Loss_G: 8.9145\n",
      "[0/25][44/782] Loss_D: 0.0010 Loss_G: 9.0814\n",
      "[0/25][45/782] Loss_D: 0.0007 Loss_G: 9.0466\n",
      "[0/25][46/782] Loss_D: 0.0010 Loss_G: 8.9999\n",
      "[0/25][47/782] Loss_D: 0.0007 Loss_G: 9.1146\n",
      "[0/25][48/782] Loss_D: 0.0008 Loss_G: 9.2349\n",
      "[0/25][49/782] Loss_D: 0.0006 Loss_G: 9.1564\n",
      "[0/25][50/782] Loss_D: 0.0010 Loss_G: 8.9235\n",
      "[0/25][51/782] Loss_D: 0.0008 Loss_G: 9.2023\n",
      "[0/25][52/782] Loss_D: 0.0004 Loss_G: 9.4186\n",
      "[0/25][53/782] Loss_D: 0.0007 Loss_G: 9.0164\n",
      "[0/25][54/782] Loss_D: 0.0006 Loss_G: 9.3596\n",
      "[0/25][55/782] Loss_D: 0.0006 Loss_G: 9.2802\n",
      "[0/25][56/782] Loss_D: 0.0007 Loss_G: 9.3470\n",
      "[0/25][57/782] Loss_D: 0.0005 Loss_G: 9.3910\n",
      "[0/25][58/782] Loss_D: 0.0006 Loss_G: 9.3503\n",
      "[0/25][59/782] Loss_D: 0.0004 Loss_G: 9.4534\n",
      "[0/25][60/782] Loss_D: 0.0004 Loss_G: 9.5493\n",
      "[0/25][61/782] Loss_D: 0.0005 Loss_G: 9.4449\n",
      "[0/25][62/782] Loss_D: 0.0006 Loss_G: 9.5473\n",
      "[0/25][63/782] Loss_D: 0.0007 Loss_G: 9.4451\n",
      "[0/25][64/782] Loss_D: 0.0007 Loss_G: 9.3957\n",
      "[0/25][65/782] Loss_D: 0.0005 Loss_G: 9.2048\n",
      "[0/25][66/782] Loss_D: 0.0005 Loss_G: 9.6225\n",
      "[0/25][67/782] Loss_D: 0.0003 Loss_G: 9.6150\n",
      "[0/25][68/782] Loss_D: 0.0005 Loss_G: 9.6010\n",
      "[0/25][69/782] Loss_D: 0.0005 Loss_G: 9.4683\n",
      "[0/25][70/782] Loss_D: 0.0005 Loss_G: 9.7085\n",
      "[0/25][71/782] Loss_D: 0.0004 Loss_G: 9.9697\n",
      "[0/25][72/782] Loss_D: 0.0004 Loss_G: 9.8758\n",
      "[0/25][73/782] Loss_D: 0.0003 Loss_G: 9.5528\n",
      "[0/25][74/782] Loss_D: 0.0004 Loss_G: 9.7624\n",
      "[0/25][75/782] Loss_D: 0.0005 Loss_G: 9.6569\n",
      "[0/25][76/782] Loss_D: 0.0004 Loss_G: 9.7195\n",
      "[0/25][77/782] Loss_D: 0.0004 Loss_G: 9.8971\n",
      "[0/25][78/782] Loss_D: 0.0005 Loss_G: 9.4477\n",
      "[0/25][79/782] Loss_D: 0.0004 Loss_G: 9.9045\n",
      "[0/25][80/782] Loss_D: 0.0003 Loss_G: 9.6362\n",
      "[0/25][81/782] Loss_D: 0.0005 Loss_G: 9.8826\n",
      "[0/25][82/782] Loss_D: 0.0004 Loss_G: 9.9615\n",
      "[0/25][83/782] Loss_D: 0.0003 Loss_G: 10.0414\n",
      "[0/25][84/782] Loss_D: 0.0003 Loss_G: 9.8527\n",
      "[0/25][85/782] Loss_D: 0.0002 Loss_G: 9.9294\n",
      "[0/25][86/782] Loss_D: 0.0003 Loss_G: 9.8899\n",
      "[0/25][87/782] Loss_D: 0.0003 Loss_G: 9.8076\n",
      "[0/25][88/782] Loss_D: 0.0004 Loss_G: 9.8565\n",
      "[0/25][89/782] Loss_D: 0.0004 Loss_G: 9.9842\n",
      "[0/25][90/782] Loss_D: 0.0003 Loss_G: 9.7690\n",
      "[0/25][91/782] Loss_D: 0.0003 Loss_G: 10.1210\n",
      "[0/25][92/782] Loss_D: 0.0004 Loss_G: 9.8552\n",
      "[0/25][93/782] Loss_D: 0.0002 Loss_G: 10.2013\n",
      "[0/25][94/782] Loss_D: 0.0003 Loss_G: 10.0966\n",
      "[0/25][95/782] Loss_D: 0.0004 Loss_G: 9.9063\n",
      "[0/25][96/782] Loss_D: 0.0003 Loss_G: 9.9816\n",
      "[0/25][97/782] Loss_D: 0.0003 Loss_G: 10.0195\n",
      "[0/25][98/782] Loss_D: 0.0002 Loss_G: 10.2476\n",
      "[0/25][99/782] Loss_D: 0.0002 Loss_G: 9.9962\n",
      "[0/25][100/782] Loss_D: 0.0003 Loss_G: 9.7929\n",
      "[0/25][101/782] Loss_D: 0.0003 Loss_G: 10.1374\n",
      "[0/25][102/782] Loss_D: 0.0002 Loss_G: 10.0799\n",
      "[0/25][103/782] Loss_D: 0.0002 Loss_G: 10.3871\n",
      "[0/25][104/782] Loss_D: 0.0002 Loss_G: 10.5007\n",
      "[0/25][105/782] Loss_D: 0.0003 Loss_G: 10.4366\n",
      "[0/25][106/782] Loss_D: 0.0002 Loss_G: 10.1484\n",
      "[0/25][107/782] Loss_D: 0.0003 Loss_G: 10.3027\n",
      "[0/25][108/782] Loss_D: 0.0003 Loss_G: 10.2801\n",
      "[0/25][109/782] Loss_D: 0.0002 Loss_G: 10.2174\n",
      "[0/25][110/782] Loss_D: 0.0002 Loss_G: 10.4167\n",
      "[0/25][111/782] Loss_D: 0.0002 Loss_G: 10.3712\n",
      "[0/25][112/782] Loss_D: 0.0002 Loss_G: 10.4759\n",
      "[0/25][113/782] Loss_D: 0.0002 Loss_G: 10.2096\n",
      "[0/25][114/782] Loss_D: 0.0003 Loss_G: 10.3919\n",
      "[0/25][115/782] Loss_D: 0.0002 Loss_G: 10.5776\n",
      "[0/25][116/782] Loss_D: 0.0001 Loss_G: 10.6061\n",
      "[0/25][117/782] Loss_D: 0.0002 Loss_G: 10.5104\n",
      "[0/25][118/782] Loss_D: 0.0002 Loss_G: 10.4964\n",
      "[0/25][119/782] Loss_D: 0.0002 Loss_G: 10.4251\n",
      "[0/25][120/782] Loss_D: 0.0002 Loss_G: 10.5280\n",
      "[0/25][121/782] Loss_D: 0.0002 Loss_G: 10.5338\n",
      "[0/25][122/782] Loss_D: 0.0003 Loss_G: 10.2595\n",
      "[0/25][123/782] Loss_D: 0.0002 Loss_G: 10.3156\n",
      "[0/25][124/782] Loss_D: 0.0002 Loss_G: 10.5079\n",
      "[0/25][125/782] Loss_D: 0.0002 Loss_G: 10.4068\n",
      "[0/25][126/782] Loss_D: 0.0002 Loss_G: 10.3450\n",
      "[0/25][127/782] Loss_D: 0.0002 Loss_G: 10.3121\n",
      "[0/25][128/782] Loss_D: 0.0002 Loss_G: 10.7648\n",
      "[0/25][129/782] Loss_D: 0.0002 Loss_G: 10.5493\n",
      "[0/25][130/782] Loss_D: 0.0001 Loss_G: 10.3521\n",
      "[0/25][131/782] Loss_D: 0.0001 Loss_G: 10.3833\n",
      "[0/25][132/782] Loss_D: 0.0001 Loss_G: 10.4311\n",
      "[0/25][133/782] Loss_D: 0.0002 Loss_G: 10.3810\n",
      "[0/25][134/782] Loss_D: 0.0001 Loss_G: 10.5518\n",
      "[0/25][135/782] Loss_D: 0.0002 Loss_G: 10.6810\n",
      "[0/25][136/782] Loss_D: 0.0002 Loss_G: 10.4756\n",
      "[0/25][137/782] Loss_D: 0.0002 Loss_G: 10.3922\n",
      "[0/25][138/782] Loss_D: 0.0002 Loss_G: 10.6182\n",
      "[0/25][139/782] Loss_D: 0.0002 Loss_G: 10.7857\n",
      "[0/25][140/782] Loss_D: 0.0001 Loss_G: 10.5815\n",
      "[0/25][141/782] Loss_D: 0.0001 Loss_G: 10.9770\n",
      "[0/25][142/782] Loss_D: 0.0002 Loss_G: 10.6760\n",
      "[0/25][143/782] Loss_D: 0.0001 Loss_G: 10.7723\n",
      "[0/25][144/782] Loss_D: 0.0002 Loss_G: 10.8241\n",
      "[0/25][145/782] Loss_D: 0.0002 Loss_G: 10.8768\n",
      "[0/25][146/782] Loss_D: 0.0001 Loss_G: 10.8726\n",
      "[0/25][147/782] Loss_D: 0.0002 Loss_G: 10.8684\n",
      "[0/25][148/782] Loss_D: 0.0001 Loss_G: 10.9186\n",
      "[0/25][149/782] Loss_D: 0.0001 Loss_G: 10.7715\n",
      "[0/25][150/782] Loss_D: 0.0001 Loss_G: 10.8248\n",
      "[0/25][151/782] Loss_D: 0.0001 Loss_G: 10.6584\n",
      "[0/25][152/782] Loss_D: 0.0001 Loss_G: 10.8017\n",
      "[0/25][153/782] Loss_D: 0.0001 Loss_G: 10.8031\n",
      "[0/25][154/782] Loss_D: 0.0001 Loss_G: 10.8205\n",
      "[0/25][155/782] Loss_D: 0.0001 Loss_G: 10.7611\n",
      "[0/25][156/782] Loss_D: 0.0001 Loss_G: 11.0539\n",
      "[0/25][157/782] Loss_D: 0.0001 Loss_G: 11.0653\n",
      "[0/25][158/782] Loss_D: 0.0001 Loss_G: 10.6542\n",
      "[0/25][159/782] Loss_D: 0.0001 Loss_G: 10.6773\n",
      "[0/25][160/782] Loss_D: 0.0001 Loss_G: 10.6473\n",
      "[0/25][161/782] Loss_D: 0.0001 Loss_G: 10.6810\n",
      "[0/25][162/782] Loss_D: 0.0001 Loss_G: 10.9416\n",
      "[0/25][163/782] Loss_D: 0.0001 Loss_G: 11.1507\n",
      "[0/25][164/782] Loss_D: 0.0001 Loss_G: 10.8529\n",
      "[0/25][165/782] Loss_D: 0.0001 Loss_G: 10.8972\n",
      "[0/25][166/782] Loss_D: 0.0001 Loss_G: 11.1117\n",
      "[0/25][167/782] Loss_D: 0.0001 Loss_G: 11.0993\n",
      "[0/25][168/782] Loss_D: 0.0001 Loss_G: 11.0639\n",
      "[0/25][169/782] Loss_D: 0.0001 Loss_G: 10.8879\n",
      "[0/25][170/782] Loss_D: 0.0002 Loss_G: 11.0026\n",
      "[0/25][171/782] Loss_D: 0.0001 Loss_G: 11.2185\n",
      "[0/25][172/782] Loss_D: 0.0001 Loss_G: 11.0712\n",
      "[0/25][173/782] Loss_D: 0.0002 Loss_G: 10.8965\n",
      "[0/25][174/782] Loss_D: 0.0001 Loss_G: 11.1213\n",
      "[0/25][175/782] Loss_D: 0.0001 Loss_G: 11.2750\n",
      "[0/25][176/782] Loss_D: 0.0001 Loss_G: 11.2131\n",
      "[0/25][177/782] Loss_D: 0.0001 Loss_G: 11.4193\n",
      "[0/25][178/782] Loss_D: 0.0001 Loss_G: 11.1075\n",
      "[0/25][179/782] Loss_D: 0.0002 Loss_G: 11.1564\n",
      "[0/25][180/782] Loss_D: 0.0001 Loss_G: 11.3734\n",
      "[0/25][181/782] Loss_D: 0.0001 Loss_G: 11.4044\n",
      "[0/25][182/782] Loss_D: 0.0001 Loss_G: 11.1269\n",
      "[0/25][183/782] Loss_D: 0.0002 Loss_G: 11.2352\n",
      "[0/25][184/782] Loss_D: 0.0001 Loss_G: 11.2497\n",
      "[0/25][185/782] Loss_D: 0.0001 Loss_G: 11.0373\n",
      "[0/25][186/782] Loss_D: 0.0001 Loss_G: 11.0132\n",
      "[0/25][187/782] Loss_D: 0.0001 Loss_G: 11.1141\n",
      "[0/25][188/782] Loss_D: 0.0001 Loss_G: 11.0136\n",
      "[0/25][189/782] Loss_D: 0.0001 Loss_G: 11.3835\n",
      "[0/25][190/782] Loss_D: 0.0001 Loss_G: 11.2318\n",
      "[0/25][191/782] Loss_D: 0.0001 Loss_G: 11.2879\n",
      "[0/25][192/782] Loss_D: 0.0001 Loss_G: 11.2664\n",
      "[0/25][193/782] Loss_D: 0.0001 Loss_G: 11.1422\n",
      "[0/25][194/782] Loss_D: 0.0001 Loss_G: 11.2508\n",
      "[0/25][195/782] Loss_D: 0.0001 Loss_G: 11.3505\n",
      "[0/25][196/782] Loss_D: 0.0001 Loss_G: 11.4113\n",
      "[0/25][197/782] Loss_D: 0.0001 Loss_G: 11.3529\n",
      "[0/25][198/782] Loss_D: 0.0001 Loss_G: 11.1043\n",
      "[0/25][199/782] Loss_D: 0.0001 Loss_G: 11.3652\n",
      "[0/25][200/782] Loss_D: 0.0001 Loss_G: 11.2153\n",
      "[0/25][201/782] Loss_D: 0.0001 Loss_G: 11.2203\n",
      "[0/25][202/782] Loss_D: 0.0001 Loss_G: 11.2069\n",
      "[0/25][203/782] Loss_D: 0.0001 Loss_G: 11.3997\n",
      "[0/25][204/782] Loss_D: 0.0001 Loss_G: 11.4372\n",
      "[0/25][205/782] Loss_D: 0.0001 Loss_G: 11.3517\n",
      "[0/25][206/782] Loss_D: 0.0001 Loss_G: 11.3444\n",
      "[0/25][207/782] Loss_D: 0.0001 Loss_G: 11.4183\n",
      "[0/25][208/782] Loss_D: 0.0001 Loss_G: 11.2432\n",
      "[0/25][209/782] Loss_D: 0.0001 Loss_G: 11.4119\n",
      "[0/25][210/782] Loss_D: 0.0001 Loss_G: 11.1288\n",
      "[0/25][211/782] Loss_D: 0.0001 Loss_G: 11.4001\n",
      "[0/25][212/782] Loss_D: 0.0001 Loss_G: 11.3399\n",
      "[0/25][213/782] Loss_D: 0.0001 Loss_G: 11.3809\n",
      "[0/25][214/782] Loss_D: 0.0001 Loss_G: 11.3765\n",
      "[0/25][215/782] Loss_D: 0.0001 Loss_G: 11.5198\n",
      "[0/25][216/782] Loss_D: 0.0001 Loss_G: 11.4750\n",
      "[0/25][217/782] Loss_D: 0.0001 Loss_G: 11.2282\n",
      "[0/25][218/782] Loss_D: 0.0001 Loss_G: 11.3265\n",
      "[0/25][219/782] Loss_D: 0.0001 Loss_G: 11.5389\n",
      "[0/25][220/782] Loss_D: 0.0001 Loss_G: 11.4580\n",
      "[0/25][221/782] Loss_D: 0.0001 Loss_G: 11.6666\n",
      "[0/25][222/782] Loss_D: 0.0001 Loss_G: 11.4590\n",
      "[0/25][223/782] Loss_D: 0.0001 Loss_G: 11.4012\n",
      "[0/25][224/782] Loss_D: 0.0001 Loss_G: 11.5186\n",
      "[0/25][225/782] Loss_D: 0.0001 Loss_G: 11.5104\n",
      "[0/25][226/782] Loss_D: 0.0001 Loss_G: 11.4869\n",
      "[0/25][227/782] Loss_D: 0.0001 Loss_G: 11.2867\n",
      "[0/25][228/782] Loss_D: 0.0001 Loss_G: 11.5357\n",
      "[0/25][229/782] Loss_D: 0.0001 Loss_G: 11.5418\n",
      "[0/25][230/782] Loss_D: 0.0001 Loss_G: 11.6373\n",
      "[0/25][231/782] Loss_D: 0.0001 Loss_G: 11.4505\n",
      "[0/25][232/782] Loss_D: 0.0001 Loss_G: 11.5399\n",
      "[0/25][233/782] Loss_D: 0.0001 Loss_G: 11.7883\n",
      "[0/25][234/782] Loss_D: 0.0001 Loss_G: 11.6191\n",
      "[0/25][235/782] Loss_D: 0.0000 Loss_G: 11.6535\n",
      "[0/25][236/782] Loss_D: 0.0001 Loss_G: 11.4682\n",
      "[0/25][237/782] Loss_D: 0.0000 Loss_G: 11.6473\n",
      "[0/25][238/782] Loss_D: 0.0001 Loss_G: 11.4935\n",
      "[0/25][239/782] Loss_D: 0.0001 Loss_G: 11.3046\n",
      "[0/25][240/782] Loss_D: 0.0001 Loss_G: 11.5516\n",
      "[0/25][241/782] Loss_D: 0.0001 Loss_G: 11.5630\n",
      "[0/25][242/782] Loss_D: 0.0001 Loss_G: 11.6973\n",
      "[0/25][243/782] Loss_D: 0.0001 Loss_G: 11.4360\n",
      "[0/25][244/782] Loss_D: 0.0001 Loss_G: 11.4963\n",
      "[0/25][245/782] Loss_D: 0.0001 Loss_G: 11.7363\n",
      "[0/25][246/782] Loss_D: 0.0000 Loss_G: 11.5500\n",
      "[0/25][247/782] Loss_D: 0.0001 Loss_G: 11.6854\n",
      "[0/25][248/782] Loss_D: 0.0001 Loss_G: 11.4891\n",
      "[0/25][249/782] Loss_D: 0.0000 Loss_G: 11.7435\n",
      "[0/25][250/782] Loss_D: 0.0001 Loss_G: 11.5275\n",
      "[0/25][251/782] Loss_D: 0.0000 Loss_G: 11.6355\n",
      "[0/25][252/782] Loss_D: 0.0000 Loss_G: 11.7245\n",
      "[0/25][253/782] Loss_D: 0.0001 Loss_G: 11.8143\n",
      "[0/25][254/782] Loss_D: 0.0001 Loss_G: 11.7896\n",
      "[0/25][255/782] Loss_D: 0.0001 Loss_G: 11.4710\n",
      "[0/25][256/782] Loss_D: 0.0001 Loss_G: 11.4535\n",
      "[0/25][257/782] Loss_D: 0.0001 Loss_G: 11.6297\n",
      "[0/25][258/782] Loss_D: 0.0000 Loss_G: 11.8308\n",
      "[0/25][259/782] Loss_D: 0.0001 Loss_G: 11.6320\n",
      "[0/25][260/782] Loss_D: 0.0001 Loss_G: 11.7797\n",
      "[0/25][261/782] Loss_D: 0.0000 Loss_G: 11.7140\n",
      "[0/25][262/782] Loss_D: 0.0000 Loss_G: 11.6672\n",
      "[0/25][263/782] Loss_D: 0.0001 Loss_G: 11.7193\n",
      "[0/25][264/782] Loss_D: 0.0001 Loss_G: 11.6297\n",
      "[0/25][265/782] Loss_D: 0.0001 Loss_G: 11.7350\n",
      "[0/25][266/782] Loss_D: 0.0000 Loss_G: 11.8086\n",
      "[0/25][267/782] Loss_D: 0.0000 Loss_G: 11.7683\n",
      "[0/25][268/782] Loss_D: 0.0001 Loss_G: 11.7833\n",
      "[0/25][269/782] Loss_D: 0.0001 Loss_G: 11.8449\n",
      "[0/25][270/782] Loss_D: 0.0000 Loss_G: 11.4992\n",
      "[0/25][271/782] Loss_D: 0.0000 Loss_G: 11.8371\n",
      "[0/25][272/782] Loss_D: 0.0001 Loss_G: 11.7769\n",
      "[0/25][273/782] Loss_D: 0.0001 Loss_G: 11.8038\n",
      "[0/25][274/782] Loss_D: 0.0000 Loss_G: 11.8398\n",
      "[0/25][275/782] Loss_D: 0.0001 Loss_G: 11.6494\n",
      "[0/25][276/782] Loss_D: 0.0001 Loss_G: 11.6823\n",
      "[0/25][277/782] Loss_D: 0.0001 Loss_G: 11.5736\n",
      "[0/25][278/782] Loss_D: 0.0000 Loss_G: 11.9594\n",
      "[0/25][279/782] Loss_D: 0.0000 Loss_G: 11.9419\n",
      "[0/25][280/782] Loss_D: 0.0001 Loss_G: 11.6119\n",
      "[0/25][281/782] Loss_D: 0.0000 Loss_G: 11.9315\n",
      "[0/25][282/782] Loss_D: 0.0000 Loss_G: 11.9483\n",
      "[0/25][283/782] Loss_D: 0.0000 Loss_G: 11.9990\n",
      "[0/25][284/782] Loss_D: 0.0001 Loss_G: 11.9043\n",
      "[0/25][285/782] Loss_D: 0.0000 Loss_G: 11.7421\n",
      "[0/25][286/782] Loss_D: 0.0001 Loss_G: 11.8813\n",
      "[0/25][287/782] Loss_D: 0.0000 Loss_G: 11.7745\n",
      "[0/25][288/782] Loss_D: 0.0001 Loss_G: 11.6306\n",
      "[0/25][289/782] Loss_D: 0.0000 Loss_G: 11.9469\n",
      "[0/25][290/782] Loss_D: 0.0000 Loss_G: 11.9652\n",
      "[0/25][291/782] Loss_D: 0.0000 Loss_G: 12.1338\n",
      "[0/25][292/782] Loss_D: 0.0000 Loss_G: 11.7444\n",
      "[0/25][293/782] Loss_D: 0.0000 Loss_G: 11.9162\n",
      "[0/25][294/782] Loss_D: 0.0001 Loss_G: 11.9631\n",
      "[0/25][295/782] Loss_D: 0.0000 Loss_G: 11.8544\n",
      "[0/25][296/782] Loss_D: 0.0001 Loss_G: 11.9870\n",
      "[0/25][297/782] Loss_D: 0.0001 Loss_G: 11.8472\n",
      "[0/25][298/782] Loss_D: 0.0000 Loss_G: 12.0785\n",
      "[0/25][299/782] Loss_D: 0.0000 Loss_G: 12.0118\n",
      "[0/25][300/782] Loss_D: 0.0000 Loss_G: 11.9977\n",
      "[0/25][301/782] Loss_D: 0.0001 Loss_G: 12.0216\n",
      "[0/25][302/782] Loss_D: 0.0001 Loss_G: 11.8902\n",
      "[0/25][303/782] Loss_D: 0.0001 Loss_G: 11.9206\n",
      "[0/25][304/782] Loss_D: 0.0000 Loss_G: 11.9758\n",
      "[0/25][305/782] Loss_D: 0.0000 Loss_G: 11.7915\n",
      "[0/25][306/782] Loss_D: 0.0000 Loss_G: 12.2605\n",
      "[0/25][307/782] Loss_D: 0.0000 Loss_G: 12.0803\n",
      "[0/25][308/782] Loss_D: 0.0000 Loss_G: 12.1973\n",
      "[0/25][309/782] Loss_D: 0.0001 Loss_G: 12.0864\n",
      "[0/25][310/782] Loss_D: 0.0000 Loss_G: 12.1480\n",
      "[0/25][311/782] Loss_D: 0.0000 Loss_G: 12.1711\n",
      "[0/25][312/782] Loss_D: 0.0000 Loss_G: 11.9191\n",
      "[0/25][313/782] Loss_D: 0.0001 Loss_G: 12.0816\n",
      "[0/25][314/782] Loss_D: 0.0000 Loss_G: 12.0491\n",
      "[0/25][315/782] Loss_D: 0.0001 Loss_G: 11.9498\n",
      "[0/25][316/782] Loss_D: 0.0000 Loss_G: 12.0314\n",
      "[0/25][317/782] Loss_D: 0.0000 Loss_G: 11.9545\n",
      "[0/25][318/782] Loss_D: 0.0001 Loss_G: 12.0499\n",
      "[0/25][319/782] Loss_D: 0.0000 Loss_G: 12.1037\n",
      "[0/25][320/782] Loss_D: 0.0000 Loss_G: 12.0284\n",
      "[0/25][321/782] Loss_D: 0.0000 Loss_G: 12.0197\n",
      "[0/25][322/782] Loss_D: 0.0000 Loss_G: 11.8903\n",
      "[0/25][323/782] Loss_D: 0.0001 Loss_G: 11.8923\n",
      "[0/25][324/782] Loss_D: 0.0000 Loss_G: 11.9593\n",
      "[0/25][325/782] Loss_D: 0.0000 Loss_G: 12.1993\n",
      "[0/25][326/782] Loss_D: 0.0000 Loss_G: 12.1266\n",
      "[0/25][327/782] Loss_D: 0.0000 Loss_G: 12.0766\n",
      "[0/25][328/782] Loss_D: 0.0000 Loss_G: 12.0454\n",
      "[0/25][329/782] Loss_D: 0.0000 Loss_G: 12.0657\n",
      "[0/25][330/782] Loss_D: 0.0000 Loss_G: 12.1372\n",
      "[0/25][331/782] Loss_D: 0.0000 Loss_G: 12.0076\n",
      "[0/25][332/782] Loss_D: 0.0001 Loss_G: 12.1601\n",
      "[0/25][333/782] Loss_D: 0.0000 Loss_G: 12.0439\n",
      "[0/25][334/782] Loss_D: 0.0000 Loss_G: 12.1147\n",
      "[0/25][335/782] Loss_D: 0.0000 Loss_G: 12.1928\n",
      "[0/25][336/782] Loss_D: 0.0000 Loss_G: 12.0834\n",
      "[0/25][337/782] Loss_D: 0.0000 Loss_G: 12.0865\n",
      "[0/25][338/782] Loss_D: 0.0000 Loss_G: 12.1094\n",
      "[0/25][339/782] Loss_D: 0.0000 Loss_G: 12.1661\n",
      "[0/25][340/782] Loss_D: 0.0000 Loss_G: 12.3945\n",
      "[0/25][341/782] Loss_D: 0.0000 Loss_G: 12.2660\n",
      "[0/25][342/782] Loss_D: 0.0000 Loss_G: 12.2185\n",
      "[0/25][343/782] Loss_D: 0.0000 Loss_G: 12.1655\n",
      "[0/25][344/782] Loss_D: 0.0001 Loss_G: 12.3557\n",
      "[0/25][345/782] Loss_D: 0.0000 Loss_G: 12.1541\n",
      "[0/25][346/782] Loss_D: 0.0000 Loss_G: 12.0817\n",
      "[0/25][347/782] Loss_D: 0.0000 Loss_G: 12.1644\n",
      "[0/25][348/782] Loss_D: 0.0000 Loss_G: 11.9669\n",
      "[0/25][349/782] Loss_D: 0.0000 Loss_G: 12.2163\n",
      "[0/25][350/782] Loss_D: 0.0000 Loss_G: 12.0485\n",
      "[0/25][351/782] Loss_D: 0.0000 Loss_G: 12.1414\n",
      "[0/25][352/782] Loss_D: 0.0000 Loss_G: 12.2269\n",
      "[0/25][353/782] Loss_D: 0.0000 Loss_G: 12.3343\n",
      "[0/25][354/782] Loss_D: 0.0000 Loss_G: 12.3647\n",
      "[0/25][355/782] Loss_D: 0.0000 Loss_G: 12.3792\n",
      "[0/25][356/782] Loss_D: 0.0000 Loss_G: 12.2468\n",
      "[0/25][357/782] Loss_D: 0.0000 Loss_G: 12.0407\n",
      "[0/25][358/782] Loss_D: 0.0000 Loss_G: 12.2813\n",
      "[0/25][359/782] Loss_D: 0.0000 Loss_G: 12.3152\n",
      "[0/25][360/782] Loss_D: 0.0000 Loss_G: 12.0539\n",
      "[0/25][361/782] Loss_D: 0.0000 Loss_G: 12.2450\n",
      "[0/25][362/782] Loss_D: 0.0000 Loss_G: 12.2844\n",
      "[0/25][363/782] Loss_D: 0.0000 Loss_G: 12.5012\n",
      "[0/25][364/782] Loss_D: 0.0000 Loss_G: 12.4177\n",
      "[0/25][365/782] Loss_D: 0.0000 Loss_G: 12.2601\n",
      "[0/25][366/782] Loss_D: 0.0000 Loss_G: 12.3974\n",
      "[0/25][367/782] Loss_D: 0.0000 Loss_G: 12.2149\n",
      "[0/25][368/782] Loss_D: 0.0000 Loss_G: 12.4524\n",
      "[0/25][369/782] Loss_D: 0.0000 Loss_G: 12.3244\n",
      "[0/25][370/782] Loss_D: 0.0000 Loss_G: 12.3266\n",
      "[0/25][371/782] Loss_D: 0.0000 Loss_G: 12.2155\n",
      "[0/25][372/782] Loss_D: 0.0000 Loss_G: 12.1100\n",
      "[0/25][373/782] Loss_D: 0.0000 Loss_G: 12.2663\n",
      "[0/25][374/782] Loss_D: 0.0000 Loss_G: 12.2368\n",
      "[0/25][375/782] Loss_D: 0.0000 Loss_G: 12.2429\n",
      "[0/25][376/782] Loss_D: 0.0000 Loss_G: 11.9949\n",
      "[0/25][377/782] Loss_D: 0.0000 Loss_G: 12.4132\n",
      "[0/25][378/782] Loss_D: 0.0000 Loss_G: 12.2184\n",
      "[0/25][379/782] Loss_D: 0.0000 Loss_G: 12.3205\n",
      "[0/25][380/782] Loss_D: 0.0000 Loss_G: 12.1987\n",
      "[0/25][381/782] Loss_D: 0.0000 Loss_G: 12.2236\n",
      "[0/25][382/782] Loss_D: 0.0000 Loss_G: 12.3931\n",
      "[0/25][383/782] Loss_D: 0.0000 Loss_G: 12.2820\n",
      "[0/25][384/782] Loss_D: 0.0000 Loss_G: 12.4989\n",
      "[0/25][385/782] Loss_D: 0.0000 Loss_G: 12.3367\n",
      "[0/25][386/782] Loss_D: 0.0000 Loss_G: 12.1782\n",
      "[0/25][387/782] Loss_D: 0.0000 Loss_G: 12.3761\n",
      "[0/25][388/782] Loss_D: 0.0000 Loss_G: 12.5202\n",
      "[0/25][389/782] Loss_D: 0.0000 Loss_G: 12.4242\n",
      "[0/25][390/782] Loss_D: 0.0000 Loss_G: 12.4171\n",
      "[0/25][391/782] Loss_D: 0.0000 Loss_G: 12.3559\n",
      "[0/25][392/782] Loss_D: 0.0000 Loss_G: 12.3819\n",
      "[0/25][393/782] Loss_D: 0.0000 Loss_G: 12.2274\n",
      "[0/25][394/782] Loss_D: 0.0000 Loss_G: 12.2250\n",
      "[0/25][395/782] Loss_D: 0.0000 Loss_G: 12.5971\n",
      "[0/25][396/782] Loss_D: 0.0000 Loss_G: 12.3197\n",
      "[0/25][397/782] Loss_D: 0.0000 Loss_G: 12.6408\n",
      "[0/25][398/782] Loss_D: 0.0000 Loss_G: 12.2634\n",
      "[0/25][399/782] Loss_D: 0.0000 Loss_G: 12.1712\n",
      "[0/25][400/782] Loss_D: 0.0000 Loss_G: 12.2392\n",
      "[0/25][401/782] Loss_D: 0.0000 Loss_G: 12.3675\n",
      "[0/25][402/782] Loss_D: 0.0000 Loss_G: 12.5052\n",
      "[0/25][403/782] Loss_D: 0.0000 Loss_G: 12.5233\n",
      "[0/25][404/782] Loss_D: 0.0000 Loss_G: 12.6053\n",
      "[0/25][405/782] Loss_D: 0.0000 Loss_G: 12.4825\n",
      "[0/25][406/782] Loss_D: 0.0000 Loss_G: 12.5801\n",
      "[0/25][407/782] Loss_D: 0.0000 Loss_G: 12.2730\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-66f511503f07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Training the discriminator with a fake image generated by generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# made a random input vector (noise) of the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# we forward propagate this random input vector into nn of generator to get some fake generated image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# we get the target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# we forward propagate the fake generated image into the network of the discriminator to get the prediction between 0 or 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mytf2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-31c6826f901b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     25\u001b[0m         ''' it takes in the network, forward propagate and returns \n\u001b[1;32m     26\u001b[0m         the generated image'''\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# forward propagate through whole nw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;31m# return o/p containint generated image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mytf2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mytf2/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mytf2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mytf2/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    927\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    928\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/wajeeh-machine/anaconda3/envs/mytf2/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/wajeeh-machine/anaconda3/envs/mytf2/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/wajeeh-machine/anaconda3/envs/mytf2/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/wajeeh-machine/anaconda3/envs/mytf2/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(total_epochs):\n",
    "    for i, data in enumerate(dataloader, 0): # iterate over image of dataset\n",
    "        # 1st step: Updating weights of neural network of discriminator\n",
    "        netD.zero_grad() # we initialize to 0 the gradients of the discriminator w.r.t its weights\n",
    "        # Training discriminator with real image of the dataset which will be used to train the discriminator\n",
    "        real, _ = data # we get a real image of dataset which will train the discriminator\n",
    "        input = Variable(real) # we wrap it in a Variable\n",
    "        target = Variable(torch.ones(input.size()[0])) # we get the target\n",
    "        output = netD(input) # we forward propagate this real image into nn of discriminator to get prediction between 1 or 0\n",
    "        errD_real = criterion(output, target) # we compute loss b/w predictions op and target equal to 1\n",
    "        \n",
    "        # Training the discriminator with a fake image generated by generator\n",
    "        noise = Variable(torch.randn(input.size()[0], 100, 1, 1)) # made a random input vector (noise) of the generator\n",
    "        fake = netG(noise) # we forward propagate this random input vector into nn of generator to get some fake generated image\n",
    "        target = Variable(torch.zeros(input.size()[0])) # we get the target\n",
    "        output = netD(fake.detach()) # we forward propagate the fake generated image into the network of the discriminator to get the prediction between 0 or 1\n",
    "        errD_fake = criterion(output, target) # we compute thhe loss b/w prediction (output) and the target (equal to 0)\n",
    "        \n",
    "        #BCK PROPAGATING THE TOTAL ERROR\n",
    "        errD = errD_real + errD_fake # we compute total error of discriminator\n",
    "        errD.backward() # we backpropagate the loss error by computing the gradients of total respect to the weights of the discriminator\n",
    "        optimizerD.step() #we apply the optimizer to update the weights according to how much they are responsible for the loss of the discriminator\n",
    "        \n",
    "        # 2nd step: updating the weights of the neural network of the generator\n",
    "        netG.zero_grad() # initialize to the 0 the gradients of the generator with respect to the weights\n",
    "        target = Variable(torch.ones(input.size()[0])) # we get the target\n",
    "        output = netD(fake) # we forward propagate the fake generated images into the neural of the discriminator to get the prediction (val bw 0 and 1)\n",
    "        errG = criterion(output, target) # we compute the loss error by computing the gradients of the total with respoect to the weights of the generator\n",
    "        optimizerG.step() # we apply optimizer to update the weights according to how much they are responsible for the loss error of the generator\n",
    "        \n",
    "        # 3rd Step: printing the losses and saving the real image and the generated image of the minibatch every 100 steps\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch, 25, i, len(dataloader), errD.item(), errG.item())) # We print les losses of the discriminator (Loss_D) and the generator (Loss_G).\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            vutils.save_image(real, '%s/real_samples.png' % \"../datasets/gan_cifar10/results/\", normalize = True) # We save the real images of the minibatch.\n",
    "            fake = netG(noise) #We get our fake generated images.\n",
    "            vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % (\"../datasets/gan_cifar10/results/\", epoch), normalize = True) # We also save the fake generated images of the minibatch.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
